{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import fastf1 as ff1\n",
    "\n",
    "ff1.Cache.enable_cache('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# ignore info messages\n",
    "import logging\n",
    "logging.getLogger('fastf1').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(s):\n",
    "    if isinstance(s, str) and s.endswith('L'):\n",
    "        return int(s.split()[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def load_api_data(session):\n",
    "    \"\"\"\n",
    "    Loads the data from the API and returns it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    laps_data, stream_data = ff1.api.timing_data(session.api_path)\n",
    "    laps_data.dropna(subset=['Time'], inplace=True)\n",
    "    \n",
    "    api_data = pd.merge_asof(laps_data.sort_values('Time'), stream_data.sort_values('Time'), on='Time', by='Driver')\n",
    "\n",
    "    merged_laps = pd.merge(session.laps, api_data[['Driver', 'Time', 'NumberOfLaps', 'NumberOfPitStops', 'Position', 'GapToLeader', 'IntervalToPositionAhead']], left_on=['LapNumber', 'DriverNumber'], right_on=['NumberOfLaps', 'Driver'])\n",
    "\n",
    "    merged_laps['LapsToLeader'] = merged_laps['GapToLeader'].map(extract_number)\n",
    "\n",
    "    merged_laps.replace(regex=r'^LAP', value=0, inplace=True)\n",
    "    merged_laps.replace(regex=r'^\\+', value='', inplace=True)\n",
    "    merged_laps.replace(regex=r'^(\\d+)\\sL$', value=np.nan, inplace=True)\n",
    "\n",
    "    merged_laps.rename(columns={'Time_x': 'Time', 'Driver_x':'Driver'}, inplace=True)\n",
    "    merged_laps = merged_laps.astype({'GapToLeader': 'float64', 'IntervalToPositionAhead': 'float64'})\n",
    "\n",
    "    return merged_laps[['Time', 'Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'PitOutTime',\n",
    "       'PitInTime','Compound', 'TyreLife', 'Stint', 'LapStartTime', 'Team',\n",
    "        'TrackStatus', 'IsAccurate', 'LapStartDate', 'NumberOfPitStops', 'Position', 'GapToLeader',\n",
    "       'IntervalToPositionAhead', 'LapsToLeader']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_dataframe():\n",
    "    return pd.DataFrame(\n",
    "            columns=[\n",
    "                'LapStartTime',\n",
    "                'LapNumber',\n",
    "                'LapTime',\n",
    "                'DriverNumber',\n",
    "                'Team',\n",
    "                'Compound',\n",
    "                'TyreLife',\n",
    "                'TrackStatus',\n",
    "                'Stint',\n",
    "                'DistanceToDriverAhead',\n",
    "                'DriverAhead',\n",
    "                'PitStatus',\n",
    "                'IsAccurate',\n",
    "                'NumberOfPitStops',\n",
    "                'Position',\n",
    "                'GapToLeader',\n",
    "                'IntervalToPositionAhead',\n",
    "                'LapsToLeader',\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception that is raised when there is no telemetry data for a given lap.\n",
    "class NoTelemetryException(Exception):\n",
    "    pass\n",
    "\n",
    "# Find the telemetry data (Driver Ahead, Distance to Driver Ahead) for the start of a lap and merge it with the lap data.\n",
    "\n",
    "\n",
    "def get_telemetry_at_start_of_lap(lap, telemetry):\n",
    "    # Find the telemetry data for the start of the lap by creating a 1 second window around the lap start time.\n",
    "    mask = (telemetry['Date'] > lap['LapStartDate']) & (\n",
    "        telemetry['Date'] <= lap['LapStartDate'] + pd.Timedelta(seconds=1))\n",
    "    rows = telemetry.loc[mask]\n",
    "    # If there is no telemetry data for the lap, raise an exception.\n",
    "    if rows.empty:\n",
    "        raise NoTelemetryException(\"No telemetry data found for lap \" + str(\n",
    "            lap['LapNumber']) + \" of \" + str(lap['Driver']) + \" at \" + str(lap['LapStartDate']))\n",
    "    # There can be multiple telemetry samples in the 1 second window, so take the first one.\n",
    "    row = rows.iloc[0]\n",
    "    # Get the telemetry data we are interested in.\n",
    "    telemetryInfo = row[['DriverAhead', 'DistanceToDriverAhead']]\n",
    "    lapInfo = lap[['LapStartTime', 'LapNumber', 'LapTime',\n",
    "                   'DriverNumber', 'Team', 'Compound', \n",
    "                   'TyreLife', 'Stint', 'TrackStatus',\n",
    "                   'IsAccurate', 'NumberOfPitStops', 'Position',\n",
    "                   'GapToLeader', 'IntervalToPositionAhead', 'LapsToLeader',]]  # Get the lap data we are interested in.\n",
    "    # Convert the pit out time to seconds.\n",
    "    lap['PitOutTime'] = lap['PitOutTime'].total_seconds() if lap['PitOutTime'] is not None else 0\n",
    "    # Convert the pit in time to seconds.\n",
    "    lap['PitInTime'] = lap['PitInTime'].total_seconds() if lap['PitInTime'] is not None else 0\n",
    "    # Get the pit status.\n",
    "    lapInfo['PitStatus'] = 'OutLap' if lap['PitOutTime'] > 0 else 'InLap' if lap['PitInTime'] > 0 else 'NoPit'\n",
    "    telemetryInfo.rename(\"Telemetry\", inplace=True)\n",
    "    lapInfo.rename(\"Lap\", inplace=True)\n",
    "    # Merge the telemetry and lap data.\n",
    "    merge = pd.concat([telemetryInfo, lapInfo])\n",
    "    return merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exception that is raised when there is no data for a given lap.\n",
    "class NoLapException(Exception):\n",
    "    pass\n",
    "\n",
    "# Find all the laps for a given driver and merge the telemetry data for the start of each lap.\n",
    "def get_laps_of_driver(driver, laps):\n",
    "    driver_laps = laps.loc[laps['DriverNumber'] == driver]\n",
    "    if len(driver_laps['DriverNumber']) == 0:\n",
    "        raise NoLapException(\"No laps for driver \" + driver)\n",
    "    driver_laps_telemetry = driver_laps.get_car_data()\n",
    "    if len(driver_laps_telemetry) == 0:\n",
    "        raise NoLapException(\"No telemetry for driver \" + driver)\n",
    "    try:\n",
    "        driver_laps_telemetry = driver_laps_telemetry.add_driver_ahead()\n",
    "        transformed_laps = []\n",
    "        for index, row in driver_laps.iterrows():\n",
    "            try:\n",
    "                transformed_laps.append(get_telemetry_at_start_of_lap(row, driver_laps_telemetry))\n",
    "            except NoTelemetryException as e:\n",
    "                print(e)\n",
    "    except ValueError as e:\n",
    "        print(\"error : \", e)\n",
    "        print(driver_laps_telemetry)\n",
    "        return get_empty_dataframe()\n",
    "    return pd.DataFrame(transformed_laps)\n",
    "\n",
    "# Add weather data that would have been available at the start of each lap.\n",
    "def add_weather_to_laps(laps, weather):\n",
    "    if laps.empty:\n",
    "        raise NoLapException(\"Laps dataframe is empty\")\n",
    "    # Effectuer une jointure bas√©e sur une plage de temps\n",
    "    lapsWithWeather = pd.merge_asof(laps.sort_values('LapStartTime'), \n",
    "                                    weather.sort_values('Time'), \n",
    "                                    left_on='LapStartTime', \n",
    "                                    right_on='Time', \n",
    "                                    by=None, \n",
    "                                    direction='backward')\n",
    "\n",
    "    return lapsWithWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the data for all the races within a given year and save it to csv files.\n",
    "def get_season_data(year, save_all_races=True):\n",
    "    schedule = ff1.get_event_schedule(year, include_testing=False)\n",
    "    \n",
    "    path = 'data/' + str(year)\n",
    "    # Create a directory for the year if it doesn't exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    df_season = get_empty_dataframe()\n",
    "    for index, event in schedule.iterrows():\n",
    "        if year == 2018 and event['RoundNumber'] < 3: # The 2 first races of 2018 do not have telemetry data\n",
    "            continue\n",
    "        print(\"Processing race round - \", event['RoundNumber'])\n",
    "        race = event.get_race()\n",
    "        race.load()\n",
    "        df_event = get_empty_dataframe()\n",
    "        api_laps = load_api_data(race)\n",
    "        \n",
    "\n",
    "        for driver in race.drivers:\n",
    "            print(\"     Processing driver - \", driver)\n",
    "            try:\n",
    "                df_event = pd.concat([df_event, get_laps_of_driver(driver, api_laps)])\n",
    "            except NoLapException as e:\n",
    "                print(e)\n",
    "    \n",
    "        df_event['Track'] = event['Location']\n",
    "        df_event['TotalLaps'] = api_laps['LapNumber'].max()\n",
    "        df_event['Year'] = year\n",
    "        try:\n",
    "            df_event = add_weather_to_laps(df_event, race.weather_data)\n",
    "            df_event = df_event.drop(columns=['Time'])\n",
    "            # Convert the laptime column to total seconds if it's not a NAN value\n",
    "            df_event['LapTime'] = df_event['LapTime'].apply(lambda x: x.total_seconds() if not pd.isna(x) else x)\n",
    "            df_event['LapStartTime'] = df_event['LapStartTime'].apply(lambda x: x.total_seconds() if not pd.isna(x) else x)\n",
    "        except NoLapException as e:\n",
    "            print(e)\n",
    "        if save_all_races:\n",
    "            # Save it to a csv file\n",
    "            df_event.to_csv(path + '/' + event.EventName.replace(' ', '_').lower() + '.csv', index=False)\n",
    "        df_season = pd.concat([df_season, df_event], axis=0)\n",
    "    # Save the data for the whole season\n",
    "    df_season.to_csv(path + '/season.csv', index=False)\n",
    "    return df_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Chinese Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing race round -  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['3', '77', '7', '44', '33', '27', '14', '5', '55', '20', '31', '11', '2', '18', '35', '9', '8', '10', '16', '28']\n",
      "api            INFO \tUsing cached data for timing_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Processing driver -  3\n",
      "     Processing driver -  77\n",
      "     Processing driver -  7\n",
      "     Processing driver -  44\n",
      "     Processing driver -  33\n",
      "     Processing driver -  27\n",
      "     Processing driver -  14\n",
      "     Processing driver -  5\n",
      "     Processing driver -  55\n",
      "     Processing driver -  20\n",
      "     Processing driver -  31\n",
      "     Processing driver -  11\n",
      "     Processing driver -  2\n",
      "     Processing driver -  18\n",
      "     Processing driver -  35\n",
      "     Processing driver -  9\n",
      "     Processing driver -  8\n",
      "     Processing driver -  10\n",
      "     Processing driver -  16\n",
      "     Processing driver -  28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "core           INFO \tLoading data for Azerbaijan Grand Prix - Race [v2.3.0]\n",
      "api            INFO \tUsing cached data for driver_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing race round -  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "api            INFO \tUsing cached data for timing_data\n",
      "api            INFO \tUsing cached data for timing_app_data\n",
      "core           INFO \tProcessing timing data...\n",
      "api            INFO \tUsing cached data for session_status_data\n",
      "api            INFO \tUsing cached data for track_status_data\n",
      "core        WARNING \tDriver 55: Lap timing integrity check failed for 1 lap(s)\n",
      "api            INFO \tUsing cached data for car_data\n",
      "api            INFO \tUsing cached data for position_data\n",
      "api            INFO \tUsing cached data for weather_data\n",
      "api            INFO \tUsing cached data for race_control_messages\n",
      "core           INFO \tFinished loading data for 20 drivers: ['44', '7', '11', '5', '55', '16', '14', '18', '2', '28', '9', '10', '20', '77', '8', '33', '3', '27', '31', '35']\n",
      "api            INFO \tUsing cached data for timing_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Processing driver -  44\n",
      "     Processing driver -  7\n",
      "     Processing driver -  11\n",
      "     Processing driver -  5\n",
      "     Processing driver -  55\n",
      "     Processing driver -  16\n",
      "     Processing driver -  14\n",
      "     Processing driver -  18\n",
      "     Processing driver -  2\n",
      "     Processing driver -  28\n",
      "     Processing driver -  9\n",
      "     Processing driver -  10\n",
      "     Processing driver -  20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m year \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2018\u001b[39m, \u001b[39m2024\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     get_season_data(year)\n",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m, in \u001b[0;36mget_season_data\u001b[1;34m(year, save_all_races)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m     Processing driver - \u001b[39m\u001b[39m\"\u001b[39m, driver)\n\u001b[0;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     df_event \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_event, get_laps_of_driver(driver, api_laps)])\n\u001b[0;32m     27\u001b[0m \u001b[39mexcept\u001b[39;00m NoLapException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     28\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m, in \u001b[0;36mget_laps_of_driver\u001b[1;34m(driver, laps)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m driver_laps\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m     17\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m         transformed_laps\u001b[39m.\u001b[39mappend(get_telemetry_at_start_of_lap(row, driver_laps_telemetry))\n\u001b[0;32m     19\u001b[0m     \u001b[39mexcept\u001b[39;00m NoTelemetryException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     20\u001b[0m         \u001b[39mprint\u001b[39m(e)\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mget_telemetry_at_start_of_lap\u001b[1;34m(lap, telemetry)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_telemetry_at_start_of_lap\u001b[39m(lap, telemetry):\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Find the telemetry data for the start of the lap by creating a 1 second window around the lap start time.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     mask \u001b[39m=\u001b[39m (telemetry[\u001b[39m'\u001b[39;49m\u001b[39mDate\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39;49m lap[\u001b[39m'\u001b[39;49m\u001b[39mLapStartDate\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m&\u001b[39m (\n\u001b[0;32m     11\u001b[0m         telemetry[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lap[\u001b[39m'\u001b[39m\u001b[39mLapStartDate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m pd\u001b[39m.\u001b[39mTimedelta(seconds\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     12\u001b[0m     rows \u001b[39m=\u001b[39m telemetry\u001b[39m.\u001b[39mloc[mask]\n\u001b[0;32m     13\u001b[0m     \u001b[39m# If there is no telemetry data for the lap, raise an exception.\u001b[39;00m\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\arraylike.py:58\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__gt__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__gt__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49mgt)\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   6242\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 6243\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLengths must match to compare\u001b[39m\u001b[39m\"\u001b[39m, lvalues\u001b[39m.\u001b[39mshape, rvalues\u001b[39m.\u001b[39mshape\n\u001b[0;32m    266\u001b[0m         )\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m    269\u001b[0m     (\u001b[39misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[39mor\u001b[39;00m right \u001b[39mis\u001b[39;00m NaT)\n\u001b[0;32m    270\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    271\u001b[0m ):\n\u001b[0;32m    272\u001b[0m     \u001b[39m# Call the method on lvalues\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     res_values \u001b[39m=\u001b[39m op(lvalues, rvalues)\n\u001b[0;32m    275\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(rvalues) \u001b[39mand\u001b[39;00m isna(rvalues):  \u001b[39m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[39m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m op \u001b[39mis\u001b[39;00m operator\u001b[39m.\u001b[39mne:\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\arraylike.py:58\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__gt__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__gt__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49mgt)\n",
      "File \u001b[1;32mp:\\Anaconda\\envs\\bsc\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1089\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1087\u001b[0m other_vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbox(other)\n\u001b[0;32m   1088\u001b[0m \u001b[39m# GH#37462 comparison on i8 values is almost 2x faster than M8/m8\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m result \u001b[39m=\u001b[39m op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ndarray\u001b[39m.\u001b[39;49mview(\u001b[39m\"\u001b[39;49m\u001b[39mi8\u001b[39;49m\u001b[39m\"\u001b[39;49m), other_vals\u001b[39m.\u001b[39;49mview(\u001b[39m\"\u001b[39;49m\u001b[39mi8\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m   1091\u001b[0m o_mask \u001b[39m=\u001b[39m isna(other)\n\u001b[0;32m   1092\u001b[0m mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isnan \u001b[39m|\u001b[39m o_mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for year in range(2018, 2024):\n",
    "    get_season_data(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "589d2f16c7c43e145ee42078413b0251fb200486a68306d3d62712e3312580ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
