{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook va être consacré au preprocessing du dataset et l'entrainement d'un premier modèle simple pour établir une baseline.\n",
    "\n",
    "---\n",
    "\n",
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# pandas display options\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "base_path = 'data'\n",
    "file_name = 'season.csv'\n",
    "type_dict ={\n",
    "    'LapStartTime': np.float32,\n",
    "    'LapNumber': np.uint8,\n",
    "    'LapTime': np.float32,\n",
    "    'DriverNumber': \"category\",\n",
    "    'Team' : \"category\",\n",
    "    'Compound': \"category\",\n",
    "    'TyreLife': np.uint8,\n",
    "    'TrackStatus': \"category\",\n",
    "    'Stint': np.uint8,\n",
    "    'DistanceToDriverAhead': np.float32,\n",
    "    'DriverAhead': \"category\",\n",
    "    'PitStatus': \"category\",\n",
    "    'IsAccurate': np.bool8,\n",
    "    'Track': \"category\",\n",
    "    'NumberOfPitStops': np.uint8,\n",
    "    'Position' : np.uint8,\n",
    "    'GapToLeader' : np.float32,\n",
    "    'IntervalToPositionAhead' : np.float32,\n",
    "    'LapsToLeader' : np.uint8,\n",
    "    'TotalLaps' : np.uint8,\n",
    "    'AirTemp': np.float32,\n",
    "    'Humidity': np.float32,\n",
    "    'Pressure': np.float32,\n",
    "    'TrackTemp': np.float32,\n",
    "    'WindDirection': np.float32,\n",
    "    'WindSpeed': np.float32\n",
    "    }\n",
    "\n",
    "years = range(2019, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    path = os.path.join(base_path, str(year), file_name)\n",
    "    year_csv = pd.read_csv(\n",
    "            path,\n",
    "            dtype=type_dict,\n",
    "    )\n",
    "    year_csv['Year'] = year\n",
    "    data = pd.concat([\n",
    "        data,\n",
    "        year_csv\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TrackStatus ----------------------------------------------------------------\n",
    "\n",
    "def trackStatus_to_binary(df):\n",
    "    trackStatus = df['TrackStatus']\n",
    "    status = pd.Series(\n",
    "        np.zeros(6, dtype=np.bool8),\n",
    "        index=['Green', 'Yellow', 'SC', 'Red', 'VSC', 'SC_ending']\n",
    "    )\n",
    "    if \"1\" in trackStatus:\n",
    "        status['Green'] = True\n",
    "    if \"2\" in trackStatus:\n",
    "        status['Yellow'] = True\n",
    "    if \"4\" in trackStatus:\n",
    "        status['SC'] = True\n",
    "    if \"5\" in trackStatus:\n",
    "        status['Red'] = True\n",
    "    if \"6\" in trackStatus:\n",
    "        status['VSC'] = True\n",
    "    if \"7\" in trackStatus:\n",
    "        status['SC_ending'] = True\n",
    "    return status\n",
    "\n",
    "def process_trackStatus(df):\n",
    "    trackStatuses = df.apply(trackStatus_to_binary, axis=1)\n",
    "    return pd.concat([df.drop('TrackStatus', axis=1), trackStatuses], axis=1).reset_index(drop=True)\n",
    "\n",
    "## Missing Data ----------------------------------------------------------------\n",
    "\n",
    "def process_missing_values(df):\n",
    "    # TODO fill the missing values better\n",
    "    df.fillna({\n",
    "        'DistanceToDriverAhead': -1,\n",
    "        'GapToLeader': -1,\n",
    "        'IntervalToPositionAhead': -1,\n",
    "    }, inplace=True)\n",
    "\n",
    "    # drop all rows with missing laptime\n",
    "    df.dropna(subset=['LapTime'], inplace=True)\n",
    "    return df[df['LapNumber'] > 1]\n",
    "\n",
    "## Datatypes -------------------------------------------------------------------\n",
    "\n",
    "def process_datatypes(df):\n",
    "    # boolean\n",
    "    df['Green'] = df['Green'].astype('bool')\n",
    "    df['Yellow'] = df['Yellow'].astype('bool')\n",
    "    df['SC'] = df['SC'].astype('bool')\n",
    "    df['Red'] = df['Red'].astype('bool')\n",
    "    df['VSC'] = df['VSC'].astype('bool')\n",
    "    df['SC_ending'] = df['SC_ending'].astype('bool')\n",
    "    df['IsAccurate'] = df['IsAccurate'].astype('bool')\n",
    "    df['Rainfall'] = df['Rainfall'].astype('bool')\n",
    "    # category\n",
    "    df['DriverNumber'] = df['DriverNumber'].astype('category')\n",
    "    df['Team'] = df['Team'].astype('category')\n",
    "    df['Compound'] = df['Compound'].astype('category')\n",
    "    df['DriverAhead'] = df['DriverAhead'].astype('category')\n",
    "    df['Track'] = df['Track'].astype('category')\n",
    "    # float\n",
    "    df['LapStartTime'] = df['LapStartTime'].astype('float32')\n",
    "    df['LapTime'] = df['LapTime'].astype('float32')\n",
    "    df['DistanceToDriverAhead'] = df['DistanceToDriverAhead'].astype('float32')\n",
    "    df['GapToLeader'] = df['GapToLeader'].astype('float32')\n",
    "    df['IntervalToPositionAhead'] = df['IntervalToPositionAhead'].astype('float32')\n",
    "    df['AirTemp'] = df['AirTemp'].astype('float32')\n",
    "    df['Humidity'] = df['Humidity'].astype('float32')\n",
    "    df['Pressure'] = df['Pressure'].astype('float32')\n",
    "    df['TrackTemp'] = df['TrackTemp'].astype('float32')\n",
    "    df['WindDirection'] = df['WindDirection'].astype('float32')\n",
    "    df['WindSpeed'] = df['WindSpeed'].astype('float32')\n",
    "    # int\n",
    "    df['LapNumber'] = df['LapNumber'].astype('uint8')\n",
    "    df['TyreLife'] = df['TyreLife'].astype('uint8')\n",
    "    df['Stint'] = df['Stint'].astype('uint8')\n",
    "    df['NumberOfPitStops'] = df['NumberOfPitStops'].astype('uint8')\n",
    "    df['Position'] = df['Position'].astype('uint8')\n",
    "    df['LapsToLeader'] = df['LapsToLeader'].astype('uint8')\n",
    "    df['TotalLaps'] = df['TotalLaps'].astype('uint8')\n",
    "    return df\n",
    "\n",
    "## Add target ------------------------------------------------------------------\n",
    "\n",
    "def process_target(df):\n",
    "    df['is_pitting'] = df['PitStatus'] == 'InLap'\n",
    "    df['is_pitting'] = df['is_pitting'].astype('bool')\n",
    "    return df\n",
    "\n",
    "## Remove features -------------------------------------------------------------\n",
    "\n",
    "def process_remove_features(df):\n",
    "    df.drop(['LapStartTime', 'DriverNumber', 'Team', 'DriverAhead', \n",
    "    'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed',\n",
    "    'PitStatus', 'IsAccurate'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Feature encoding ------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def process_feature_encoding(df):\n",
    "    categorical_features = ['Compound', 'Track']\n",
    "    one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    one_hot_encoder.fit(df[categorical_features])\n",
    "    one_hot_encoded = one_hot_encoder.transform(df[categorical_features])\n",
    "    one_hot_encoded = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "    print(\"One hot : \", one_hot_encoded.shape)\n",
    "    print(\"Data : \", df.shape)\n",
    "    df = df.join(one_hot_encoded)\n",
    "    df.drop(categorical_features, axis=1, inplace=True)\n",
    "    return df, one_hot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    print('Preprocessing data...', df.shape)\n",
    "    df = process_trackStatus(df)\n",
    "    print('TrackStatus processed...', df.shape)\n",
    "    df = process_missing_values(df)\n",
    "    print('Missing values processed...', df.shape)\n",
    "    df = process_datatypes(df)\n",
    "    print('Datatypes processed...', df.shape)\n",
    "    df = process_target(df)\n",
    "    print('Target processed...', df.shape)\n",
    "    df = process_remove_features(df)\n",
    "    print('Features removed...', df.shape)\n",
    "    df, encoder = process_feature_encoding(df)\n",
    "    print('Features encoded...', df.shape)\n",
    "    return df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in p:\\anaconda\\envs\\bsc\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in p:\\anaconda\\envs\\bsc\\lib\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in p:\\anaconda\\envs\\bsc\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in p:\\anaconda\\envs\\bsc\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nelsonwork\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in p:\\anaconda\\envs\\bsc\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in p:\\anaconda\\envs\\bsc\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data... (70276, 28)\n",
      "TrackStatus processed... (70276, 33)\n",
      "Missing values processed... (67709, 33)\n",
      "Datatypes processed... (67709, 33)\n",
      "Target processed... (67709, 34)\n",
      "Features removed... (67709, 21)\n",
      "One hot :  (67709, 40)\n",
      "Data :  (67709, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\Anaconda\\envs\\bsc\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features encoded... (67709, 59)\n",
      "Preprocessing data... (17569, 28)\n",
      "TrackStatus processed... (17569, 33)\n",
      "Missing values processed... (16921, 33)\n",
      "Datatypes processed... (16921, 33)\n",
      "Target processed... (16921, 34)\n",
      "Features removed... (16921, 21)\n",
      "One hot :  (16921, 40)\n",
      "Data :  (16921, 21)\n",
      "Features encoded... (16921, 59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\Anaconda\\envs\\bsc\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df, encoder = preprocess(train_df)\n",
    "test_df, _ = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "X_train = train_df.drop(['is_pitting'], axis=1)\n",
    "y_train = train_df['is_pitting']\n",
    "\n",
    "X_test = test_df.drop(['is_pitting'], axis=1)\n",
    "y_test = test_df['is_pitting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65245, 58) (16299, 58) (65245,) (16299,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    return (specificity + sensitivity) / 2\n",
    "\n",
    "def balanced_accuracy_loss(y_true, y_pred):\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    tn = K.sum((1 - y_true) * (1 - y_pred))\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    sensitivity = tp / (tp + fn + K.epsilon())\n",
    "    return (specificity + sensitivity) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "X_test = np.array(X_test).astype(np.float32)\n",
    "y_test = np.array(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5151842961372035, 1: 16.964378575143005}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"big_batch_size_lr05_drop\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_142 (Dense)           (None, 256)               15104     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,369\n",
      "Trainable params: 58,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "# Create model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='big_batch_size_lr05_drop',)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=0.0005\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[balanced_accuracy_loss]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "64/64 [==============================] - 3s 18ms/step - loss: 12.9977 - balanced_accuracy_loss: 0.5038 - val_loss: 0.2067 - val_balanced_accuracy_loss: 0.4999\n",
      "Epoch 2/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 4.5125 - balanced_accuracy_loss: 0.5017 - val_loss: 0.5215 - val_balanced_accuracy_loss: 0.4942\n",
      "Epoch 3/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 2.5654 - balanced_accuracy_loss: 0.5011 - val_loss: 0.5996 - val_balanced_accuracy_loss: 0.4968\n",
      "Epoch 4/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 1.8117 - balanced_accuracy_loss: 0.4961 - val_loss: 0.6792 - val_balanced_accuracy_loss: 0.5014\n",
      "Epoch 5/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 1.3469 - balanced_accuracy_loss: 0.4976 - val_loss: 0.6857 - val_balanced_accuracy_loss: 0.5008\n",
      "Epoch 6/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 1.1522 - balanced_accuracy_loss: 0.4968 - val_loss: 0.6864 - val_balanced_accuracy_loss: 0.5006\n",
      "Epoch 7/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.9658 - balanced_accuracy_loss: 0.5024 - val_loss: 0.6844 - val_balanced_accuracy_loss: 0.5003\n",
      "Epoch 8/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.9180 - balanced_accuracy_loss: 0.5037 - val_loss: 0.6846 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 9/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.8554 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6848 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 10/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.8238 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6847 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 11/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.8089 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6859 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 12/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.7648 - balanced_accuracy_loss: 0.4990 - val_loss: 0.6859 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 13/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7524 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6857 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 14/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7464 - balanced_accuracy_loss: 0.5012 - val_loss: 0.6857 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 15/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7317 - balanced_accuracy_loss: 0.5010 - val_loss: 0.6861 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 16/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7344 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6869 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 17/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7290 - balanced_accuracy_loss: 0.4993 - val_loss: 0.6875 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 18/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7260 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6885 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 19/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7228 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6891 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 20/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7242 - balanced_accuracy_loss: 0.4992 - val_loss: 0.6890 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 21/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.7111 - balanced_accuracy_loss: 0.5009 - val_loss: 0.6892 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 22/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.7180 - balanced_accuracy_loss: 0.4993 - val_loss: 0.6900 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 23/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7108 - balanced_accuracy_loss: 0.4995 - val_loss: 0.6907 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 24/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7079 - balanced_accuracy_loss: 0.5009 - val_loss: 0.6902 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 25/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7106 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6911 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 26/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.7064 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6923 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 27/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7070 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6920 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 28/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.7036 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6923 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 29/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.7099 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6921 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 30/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7009 - balanced_accuracy_loss: 0.5006 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 31/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.7018 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 32/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6998 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 33/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6990 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 34/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.7037 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 35/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.7021 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 36/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6996 - balanced_accuracy_loss: 0.5005 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 37/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7021 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6946 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 38/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.7001 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 39/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6961 - balanced_accuracy_loss: 0.5004 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 40/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6989 - balanced_accuracy_loss: 0.4994 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 41/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6997 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 42/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6962 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 43/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6967 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 44/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6971 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 45/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6955 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 46/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6957 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 47/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6951 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 48/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6957 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 49/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.5007 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 50/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6967 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 51/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6973 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 52/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 53/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6962 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 54/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6983 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 55/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 56/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 57/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 58/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 59/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6957 - balanced_accuracy_loss: 0.4995 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 60/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6959 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 61/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 62/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 63/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6989 - balanced_accuracy_loss: 0.4995 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 64/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 65/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.5004 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 66/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 67/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6951 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 68/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6946 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 69/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6949 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 70/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6943 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 71/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 72/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 73/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6922 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 74/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 75/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6959 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 76/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6949 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 77/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 78/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6924 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 79/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 80/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 81/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 82/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6952 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 83/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 84/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 85/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 86/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 87/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 88/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 89/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 90/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 91/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 92/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 93/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 94/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 95/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 96/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 97/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 98/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6971 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 99/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 100/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 101/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 102/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 103/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 104/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 105/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 106/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 107/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 108/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 109/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 110/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6946 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 111/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 112/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 113/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 114/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 115/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 116/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 117/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 118/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 119/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 120/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 121/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 122/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 123/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 124/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 125/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 126/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 127/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 128/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 129/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 130/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 131/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 132/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 133/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 134/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 135/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 136/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 137/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 138/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 139/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 140/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 141/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 142/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 143/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 144/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 145/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6923 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 146/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 147/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 148/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 149/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 150/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 151/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 152/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 153/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 154/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 155/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 156/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 157/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 158/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 159/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 160/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 161/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 162/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 163/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 164/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 165/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 166/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 167/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 168/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 169/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 170/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 171/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 172/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 173/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 174/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 175/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 176/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 177/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 178/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6944 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 179/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 180/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 181/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 182/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6954 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 183/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 184/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6956 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 185/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 186/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 187/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6956 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 188/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 189/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 190/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 191/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 192/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 193/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 194/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 195/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 196/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 197/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 198/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 199/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 200/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 201/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 202/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 203/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 204/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 205/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 206/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 207/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 208/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 209/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 210/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 211/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6952 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 212/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 213/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 214/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 215/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 216/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 217/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 218/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 219/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 220/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 221/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 222/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 223/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 224/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 225/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 226/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 227/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 228/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 229/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 230/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 231/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 232/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 233/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 234/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 235/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 236/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 237/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 238/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 239/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6948 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 240/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 241/800\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 242/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 243/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6946 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 244/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 245/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6945 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 246/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 247/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 248/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6950 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 249/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6947 - balanced_accuracy_loss: 0.4996 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 250/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 251/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 252/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 253/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 254/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 255/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6949 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 256/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 257/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 258/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 259/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6968 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6943 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 260/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 261/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 262/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 263/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 264/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 265/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6973 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 266/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 267/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 268/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 269/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 270/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 271/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 272/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 273/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 274/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 275/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 276/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 277/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 278/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 279/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 280/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 281/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 282/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 283/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 284/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 285/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 286/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 287/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 288/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 289/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 290/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 291/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 292/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 293/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 294/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6943 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 295/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 296/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 297/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 298/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 299/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 300/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 301/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 302/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 303/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 304/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 305/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 306/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 307/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 308/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 309/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6959 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 310/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 311/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 312/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 313/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 314/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 315/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 316/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 317/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 318/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 319/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 320/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 321/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 322/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 323/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 324/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 325/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6943 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 326/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 327/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 328/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 329/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 330/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 331/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 332/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 333/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6962 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6946 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 334/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 335/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 336/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 337/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 338/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 339/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 340/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 341/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6919 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 342/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 343/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 344/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6947 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6922 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 345/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 346/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 347/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 348/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 349/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 350/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 351/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 352/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 353/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 354/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 355/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 356/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 357/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 358/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 359/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 360/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6996 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 361/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6963 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 362/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 363/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 364/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 365/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 366/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 367/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6968 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 368/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6967 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 369/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6952 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 370/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.7052 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 371/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6991 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 372/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6955 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 373/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 374/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6945 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 375/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6948 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 376/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6960 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 377/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 378/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 379/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6946 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 380/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 381/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 382/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 383/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 384/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 385/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6957 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 386/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 387/800\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 388/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6951 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 389/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 390/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 391/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 392/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 393/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 394/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.7030 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 395/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 396/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6982 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 397/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 398/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 399/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 400/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6973 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 401/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 402/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6944 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 403/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 404/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 405/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 406/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 407/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6928 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 408/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.7022 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 409/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 410/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 411/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 412/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 413/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 414/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6960 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 415/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 416/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6950 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 417/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 418/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 419/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 420/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 421/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 422/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 423/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 424/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 425/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 426/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 427/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 428/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 429/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 430/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 431/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 432/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 433/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 434/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 435/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 436/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 437/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 438/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 439/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 440/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 441/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 442/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 443/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6955 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 444/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 445/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 446/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 447/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 448/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 449/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6987 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 450/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 451/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 452/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 453/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 454/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 455/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6945 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 456/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 457/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 458/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 459/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 460/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 461/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 462/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 463/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 464/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 465/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 466/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 467/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 468/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 469/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6924 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 470/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 471/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 472/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 473/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 474/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 475/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 476/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 477/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 478/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 479/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6948 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 480/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 481/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 482/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 483/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 484/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 485/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 486/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 487/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 488/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 489/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 490/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 491/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 492/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 493/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 494/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 495/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 496/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 497/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 498/800\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 499/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 500/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 501/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 502/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 503/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6966 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 504/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 505/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 506/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 507/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 508/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.7000 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 509/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 510/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 511/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 512/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 513/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 514/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 515/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 516/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6958 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6921 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 517/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 518/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6949 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 519/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6960 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 520/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 521/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 522/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 523/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 524/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 525/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 526/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 527/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 528/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 529/800\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 530/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 531/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 532/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 533/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 534/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 535/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 536/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 537/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 538/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 539/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 540/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 541/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 542/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 543/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 544/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 545/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 546/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 547/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 548/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 549/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 550/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 551/800\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 552/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 553/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 554/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 555/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 556/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 557/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 558/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 559/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 560/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 561/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 562/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 563/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6979 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 564/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 565/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 566/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 567/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 568/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 569/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 570/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6962 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 571/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 572/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 573/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 574/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 575/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6952 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 576/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 577/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 578/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 579/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 580/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 581/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 582/800\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 583/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6942 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 584/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6974 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 585/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 586/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 587/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 588/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6943 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 589/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6953 - balanced_accuracy_loss: 0.4997 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 590/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 591/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 592/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 593/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 594/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 595/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 596/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 597/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 598/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 599/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 600/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 601/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 602/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 603/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 604/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 605/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 606/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 607/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 608/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 609/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 610/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 611/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 612/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 613/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 614/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 615/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 616/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 617/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6948 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 618/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 619/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 620/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 621/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7114 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 622/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6986 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 623/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 624/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 625/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 626/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6961 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 627/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 628/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 629/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 630/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 631/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 632/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 633/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 634/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 635/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 636/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 637/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 638/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 639/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 640/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 641/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 642/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 643/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 644/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.7174 - balanced_accuracy_loss: 0.5003 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 645/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 646/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 647/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6954 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 648/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 649/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 650/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 651/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6944 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 652/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 653/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 654/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.7028 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 655/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6944 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 656/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6930 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 657/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 658/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6960 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 659/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 660/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 661/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 662/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 663/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 664/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 665/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 666/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 667/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 668/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 669/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 670/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 671/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6938 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 672/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 673/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 674/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6948 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 675/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 676/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 677/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 678/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 679/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 680/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 681/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 682/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 683/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6943 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 684/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5001 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 685/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 686/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 687/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6937 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 688/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 689/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 690/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 691/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 692/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 693/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 694/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 695/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6941 - balanced_accuracy_loss: 0.4998 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 696/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 697/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 698/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 699/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 700/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 701/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 702/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 703/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 704/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 705/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 706/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 707/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 708/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 709/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 710/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 711/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 712/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 713/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 714/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 715/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 716/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 717/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 718/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 719/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 720/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 721/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 722/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 723/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 724/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 725/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 726/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 727/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 728/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 729/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 730/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 731/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6934 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 732/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 733/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 734/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 735/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6935 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 736/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6920 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 737/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6936 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 738/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 739/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 740/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 741/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 742/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 743/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 744/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6927 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 745/800\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 746/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 747/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 748/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 749/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 750/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 751/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 752/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 753/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 754/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 755/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 756/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6925 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 757/800\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 758/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 759/800\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 760/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 761/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 762/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 763/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 764/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6973 - balanced_accuracy_loss: 0.5004 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 765/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6995 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6940 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 766/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 767/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6939 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6943 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 768/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6929 - balanced_accuracy_loss: 0.5002 - val_loss: 0.6938 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 769/800\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.7312 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6942 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 770/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 771/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 772/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 773/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 774/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 775/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6952 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 776/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 777/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 778/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6939 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 779/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 780/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 781/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 782/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 783/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6928 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 784/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 785/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 786/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6926 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 787/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6937 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 788/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 789/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6931 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 790/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 791/800\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 792/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6930 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 793/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6933 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6936 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 794/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6940 - balanced_accuracy_loss: 0.4999 - val_loss: 0.6933 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 795/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6932 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 796/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6934 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 797/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6935 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 798/800\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6932 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 799/800\n",
      "64/64 [==============================] - 1s 15ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6929 - val_balanced_accuracy_loss: 0.5000\n",
      "Epoch 800/800\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.6931 - balanced_accuracy_loss: 0.5000 - val_loss: 0.6941 - val_balanced_accuracy_loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=800,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13944  1863]\n",
      " [  141   351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.88      0.93     15807\n",
      "         1.0       0.16      0.71      0.26       492\n",
      "\n",
      "    accuracy                           0.88     16299\n",
      "   macro avg       0.57      0.80      0.60     16299\n",
      "weighted avg       0.96      0.88      0.91     16299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred.round()))\n",
    "print(classification_report(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "models_dir = 'models/nn_big_batch_size_lr05'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "model.save(os.path.join(models_dir, 'model.h5'))\n",
    "encoder_path = os.path.join(models_dir, 'encoder.pkl')\n",
    "with open(encoder_path, 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['balanced_accuracy_loss'])\n",
    "plt.plot(hist.history['val_balanced_accuracy_loss'])\n",
    "plt.title('Model balanced accuracy')\n",
    "plt.ylabel('Balanced accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(os.path.join(models_dir, 'balanced_accuracy.svg'), format='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "589d2f16c7c43e145ee42078413b0251fb200486a68306d3d62712e3312580ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
