{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook va être consacré au preprocessing du dataset et l'entrainement d'un premier modèle simple pour établir une baseline.\n",
    "\n",
    "---\n",
    "\n",
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelson Jeanrenaud\\AppData\\Local\\Temp\\ipykernel_19728\\2552716592.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  'IsAccurate': np.bool8,\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# pandas display options\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "base_path = 'data'\n",
    "file_name = 'season.csv'\n",
    "type_dict ={\n",
    "    'LapStartTime': np.float32,\n",
    "    'LapNumber': np.uint8,\n",
    "    'LapTime': np.float32,\n",
    "    'DriverNumber': \"category\",\n",
    "    'Team' : \"category\",\n",
    "    'Compound': \"category\",\n",
    "    'TyreLife': np.uint8,\n",
    "    'TrackStatus': \"category\",\n",
    "    'Stint': np.uint8,\n",
    "    'DistanceToDriverAhead': np.float32,\n",
    "    'DriverAhead': \"category\",\n",
    "    'PitStatus': \"category\",\n",
    "    'IsAccurate': np.bool8,\n",
    "    'Track': \"category\",\n",
    "    'NumberOfPitStops': np.uint8,\n",
    "    'Position' : np.uint8,\n",
    "    'GapToLeader' : np.float32,\n",
    "    'IntervalToPositionAhead' : np.float32,\n",
    "    'LapsToLeader' : np.uint8,\n",
    "    'TotalLaps' : np.uint8,\n",
    "    'AirTemp': np.float32,\n",
    "    'Humidity': np.float32,\n",
    "    'Pressure': np.float32,\n",
    "    'TrackTemp': np.float32,\n",
    "    'WindDirection': np.float32,\n",
    "    'WindSpeed': np.float32\n",
    "    }\n",
    "\n",
    "years = range(2019, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    path = os.path.join(base_path, str(year), file_name)\n",
    "    year_csv = pd.read_csv(\n",
    "            path,\n",
    "            dtype=type_dict,\n",
    "    )\n",
    "    data = pd.concat([\n",
    "        data,\n",
    "        year_csv\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rainfall -------------------------------------------------------------------\n",
    "\n",
    "def process_rainfall(df): # Removes races with rain\n",
    "    rain = df.groupby(['Year', 'RoundNumber', 'DriverNumber'])['Compound'].transform(lambda x: x[x.str.contains('INTERMEDIATE|WET')].count())\n",
    "    return df[rain == 0].reset_index(drop=True)\n",
    "## Pitstops -------------------------------------------------------------------\n",
    "def process_pitstops(df):\n",
    "    df['PitStatus'] = df.groupby(['Year', 'RoundNumber', 'DriverNumber'])['PitStatus'].shift(-1, fill_value='NoPit')\n",
    "    return df\n",
    "## Incomplete races -----------------------------------------------------------\n",
    "def incomplete_races(df):\n",
    "    return df.groupby(['Year', 'RoundNumber', 'DriverNumber']).filter(lambda x: x['LapNumber'].max() + 3 >= x['TotalLaps'].max()).reset_index(drop=True)\n",
    "## TrackName ------------------------------------------------------------------\n",
    "\n",
    "def process_track_name(df):\n",
    "    df['Track'] = df['Track'].str.replace(' ', '_')\n",
    "    return df\n",
    "## TrackStatus ----------------------------------------------------------------\n",
    "\n",
    "def trackStatus_to_binary(df):\n",
    "    trackStatus = df['TrackStatus']\n",
    "    status = pd.Series(\n",
    "        np.zeros(6, dtype=np.bool8),\n",
    "        index=['Green', 'Yellow', 'SC', 'Red', 'VSC', 'SC_ending']\n",
    "    )\n",
    "    if \"1\" in trackStatus:\n",
    "        status['Green'] = True\n",
    "    if \"2\" in trackStatus:\n",
    "        status['Yellow'] = True\n",
    "    if \"4\" in trackStatus:\n",
    "        status['SC'] = True\n",
    "    if \"5\" in trackStatus:\n",
    "        status['Red'] = True\n",
    "    if \"6\" in trackStatus:\n",
    "        status['VSC'] = True\n",
    "    if \"7\" in trackStatus:\n",
    "        status['SC_ending'] = True\n",
    "    return status\n",
    "\n",
    "def process_trackStatus(df):\n",
    "    trackStatuses = df.apply(trackStatus_to_binary, axis=1)\n",
    "    return pd.concat([df.drop('TrackStatus', axis=1), trackStatuses], axis=1)\n",
    "\n",
    "## Missing Data ----------------------------------------------------------------\n",
    "\n",
    "def process_missing_values(df):\n",
    "    # TODO fill the missing values better\n",
    "    df.fillna({\n",
    "        'DistanceToDriverAhead': -1,\n",
    "        'GapToLeader': -1,\n",
    "        'IntervalToPositionAhead': -1,\n",
    "    }, inplace=True)\n",
    "\n",
    "    # drop all rows with missing laptime\n",
    "    df.dropna(subset=['LapTime'], inplace=True)\n",
    "    return df[df['LapNumber'] > 1].reset_index(drop=True)\n",
    "\n",
    "## Datatypes -------------------------------------------------------------------\n",
    "\n",
    "def process_datatypes(df):\n",
    "    # boolean\n",
    "    df['Green'] = df['Green'].astype('bool')\n",
    "    df['Yellow'] = df['Yellow'].astype('bool')\n",
    "    df['SC'] = df['SC'].astype('bool')\n",
    "    df['Red'] = df['Red'].astype('bool')\n",
    "    df['VSC'] = df['VSC'].astype('bool')\n",
    "    df['SC_ending'] = df['SC_ending'].astype('bool')\n",
    "    df['IsAccurate'] = df['IsAccurate'].astype('bool')\n",
    "    df['Rainfall'] = df['Rainfall'].astype('bool')\n",
    "    # category\n",
    "    df['DriverNumber'] = df['DriverNumber'].astype('category')\n",
    "    df['Team'] = df['Team'].astype('category')\n",
    "    #df['Compound'] = df['Compound'].astype('category')\n",
    "    df['DriverAhead'] = df['DriverAhead'].astype('category')\n",
    "    #df['Track'] = df['Track'].astype('category')\n",
    "    # float\n",
    "    df['LapStartTime'] = df['LapStartTime'].astype('float32')\n",
    "    df['LapTime'] = df['LapTime'].astype('float32')\n",
    "    df['DistanceToDriverAhead'] = df['DistanceToDriverAhead'].astype('float32')\n",
    "    df['GapToLeader'] = df['GapToLeader'].astype('float32')\n",
    "    df['IntervalToPositionAhead'] = df['IntervalToPositionAhead'].astype('float32')\n",
    "    df['AirTemp'] = df['AirTemp'].astype('float32')\n",
    "    df['Humidity'] = df['Humidity'].astype('float32')\n",
    "    df['Pressure'] = df['Pressure'].astype('float32')\n",
    "    df['TrackTemp'] = df['TrackTemp'].astype('float32')\n",
    "    df['WindDirection'] = df['WindDirection'].astype('float32')\n",
    "    df['WindSpeed'] = df['WindSpeed'].astype('float32')\n",
    "    # int\n",
    "    df['LapNumber'] = df['LapNumber'].astype('uint8')\n",
    "    df['TyreLife'] = df['TyreLife'].astype('uint8')\n",
    "    df['Stint'] = df['Stint'].astype('uint8')\n",
    "    df['NumberOfPitStops'] = df['NumberOfPitStops'].astype('uint8')\n",
    "    df['Position'] = df['Position'].astype('uint8')\n",
    "    df['LapsToLeader'] = df['LapsToLeader'].astype('uint8')\n",
    "    df['TotalLaps'] = df['TotalLaps'].astype('uint8')\n",
    "    return df\n",
    "\n",
    "## Add target ------------------------------------------------------------------\n",
    "\n",
    "def process_target(df):\n",
    "    df['is_pitting'] = df['PitStatus'] == 'InLap'\n",
    "    df['is_pitting'] = df['is_pitting'].astype('bool')\n",
    "    return df\n",
    "\n",
    "## Remove features -------------------------------------------------------------\n",
    "\n",
    "def process_remove_features(df):\n",
    "    df.drop(['LapStartTime', 'DriverNumber', 'Team', 'DriverAhead', \n",
    "    'AirTemp', 'Humidity', 'Pressure', 'Rainfall', 'TrackTemp', 'WindDirection', 'WindSpeed',\n",
    "    'PitStatus', 'IsAccurate', 'Year', 'RoundNumber', 'TotalLaps'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Add features ----\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['RacePercentage'] = df['LapNumber'] / df['TotalLaps']\n",
    "    return df\n",
    "\n",
    "## Feature encoding ------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def process_feature_encoding(df):\n",
    "    categorical_features = ['Compound', 'Track']\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    one_hot_encoder.fit(df[categorical_features])\n",
    "    one_hot_encoded = one_hot_encoder.transform(df[categorical_features])\n",
    "    one_hot_encoded = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_features))\n",
    "    print(\"One hot : \", one_hot_encoded.shape)\n",
    "    print(\"Data : \", df.shape)\n",
    "    df = df.join(one_hot_encoded)\n",
    "    df.drop(categorical_features, axis=1, inplace=True)\n",
    "    return df, one_hot_encoder\n",
    "\n",
    "def process_feature_encoding_new(df, encoder):\n",
    "    categorical_features = ['Compound', 'Track']\n",
    "    one_hot_encoded = encoder.transform(df[categorical_features])\n",
    "    one_hot_encoded = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "    df = df.join(one_hot_encoded)\n",
    "    df.drop(categorical_features, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pre_split(df):\n",
    "    df = df.copy()\n",
    "    print('Preprocessing data...', df.shape)\n",
    "    df = process_rainfall(df)\n",
    "    print('Rainfall processed...', df.shape)\n",
    "    df = incomplete_races(df)\n",
    "    df = process_pitstops(df)\n",
    "    df = add_features(df)\n",
    "    df = process_track_name(df)\n",
    "    print('TrackName processed...', df.shape)\n",
    "    df = process_missing_values(df)\n",
    "    print('Missing values processed...', df.shape)\n",
    "    return df\n",
    "\n",
    "def preprocess_post_split(df):\n",
    "    df = process_trackStatus(df)\n",
    "    print('TrackStatus processed...', df.shape)\n",
    "    df = process_datatypes(df)\n",
    "    print('Preprocessing data...', df.shape)\n",
    "    df = process_remove_features(df)\n",
    "    print('Features removed...', df.shape)\n",
    "    return df\n",
    "\n",
    "def preprocess_post_split_train(df):\n",
    "    df = df.copy()\n",
    "    df = process_target(df)\n",
    "    print('Target processed...', df.shape)\n",
    "    df, encoder = process_feature_encoding(df)\n",
    "    print('Features encoded...', df.shape)\n",
    "\n",
    "    df = preprocess_post_split(df)\n",
    "    \n",
    "    return df, encoder\n",
    "\n",
    "def preprocess_post_split_test(df, encoder):\n",
    "    df = df.copy()\n",
    "    df = process_target(df)\n",
    "    print('Target processed...', df.shape)\n",
    "    df = process_feature_encoding_new(df, encoder)\n",
    "    print('Features encoded...', df.shape)\n",
    "\n",
    "    df = preprocess_post_split(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_races_grouped(df):\n",
    "    return df.groupby(['Year', 'RoundNumber', 'DriverNumber'])\n",
    "\n",
    "def get_train_test_split(df, test_size, return_groups=False):\n",
    "    groups = get_races_grouped(df).groups\n",
    "    groups_keys = list(groups.keys())\n",
    "    np.random.shuffle(groups_keys)\n",
    "    test_groups = groups_keys[:int(len(groups_keys) * test_size)]\n",
    "    train_groups = groups_keys[int(len(groups_keys) * test_size):]\n",
    "    test = df[df.apply(lambda x: (x['Year'], x['RoundNumber'], x['DriverNumber']) in test_groups, axis=1)].reset_index(drop=True)\n",
    "    train = df[df.apply(lambda x: (x['Year'], x['RoundNumber'], x['DriverNumber']) in train_groups, axis=1)].reset_index(drop=True)\n",
    "    if return_groups:\n",
    "        return train, test, train.groupby(['Year', 'RoundNumber', 'DriverNumber']).groups, test.groupby(['Year', 'RoundNumber', 'DriverNumber']).groups\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data... (89139, 29)\n",
      "Rainfall processed... (78346, 29)\n",
      "TrackName processed... (73105, 29)\n",
      "Missing values processed... (70689, 29)\n",
      "Target processed... (56907, 30)\n",
      "One hot :  (56907, 32)\n",
      "Data :  (56907, 30)\n",
      "Features encoded... (56907, 60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelson Jeanrenaud\\AppData\\Local\\Temp\\ipykernel_19728\\1903073571.py:23: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.zeros(6, dtype=np.bool8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrackStatus processed... (56907, 65)\n",
      "Preprocessing data... (56907, 65)\n",
      "Features removed... (56907, 50)\n",
      "Target processed... (13782, 30)\n",
      "Features encoded... (13782, 60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nelson Jeanrenaud\\AppData\\Local\\Temp\\ipykernel_19728\\1903073571.py:23: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.zeros(6, dtype=np.bool8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrackStatus processed... (13782, 65)\n",
      "Preprocessing data... (13782, 65)\n",
      "Features removed... (13782, 50)\n",
      "(56907, 49) (13782, 49) (56907,) (13782,)\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "df = preprocess_pre_split(df)\n",
    "\n",
    "train_df, test_df, train_groups, test_groups = get_train_test_split(df.copy(), test_size=0.2, return_groups=True)\n",
    "\n",
    "train_df, encoder = preprocess_post_split_train(train_df)\n",
    "test_df = preprocess_post_split_test(test_df, encoder)\n",
    "\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "X_train = train_df.drop(['is_pitting'], axis=1)\n",
    "y_train = train_df['is_pitting']\n",
    "\n",
    "X_test = test_df.drop(['is_pitting'], axis=1)\n",
    "y_test = test_df['is_pitting']\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def specificity(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    return (specificity + sensitivity) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000, 2000],\n",
    "    'max_depth': [5, 20, None],\n",
    "    'class_weight': ['balanced_subsample', 'balanced'],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'criterion': ['entropy']\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "def custom_scorer(ypred, y):\n",
    "    return f1_score(y, ypred, average='weighted')\n",
    "\n",
    "scorer = make_scorer(\n",
    "    f1_score,\n",
    "    greater_is_better=True,\n",
    "    needs_proba=False\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=4,\n",
    "    scoring=scorer,\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m.\u001b[39;49mvalues, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\joblib\\parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1941\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1944\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\joblib\\parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1587\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1590\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1698\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1699\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m   1700\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13001121179827513\n",
      "{'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nelson Jeanrenaud\\miniconda3\\envs\\bsc\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14276,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.predict(X_test).shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10470  3422]\n",
      " [  103   281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.75      0.86     13892\n",
      "        True       0.08      0.73      0.14       384\n",
      "\n",
      "    accuracy                           0.75     14276\n",
      "   macro avg       0.53      0.74      0.50     14276\n",
      "weighted avg       0.97      0.75      0.84     14276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "ypred = grid_search.best_estimator_.predict(X_test.values)\n",
    "print(confusion_matrix(y_test, ypred))\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "models_dir = 'models/f1_score_race_percentage'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "pickle.dump(model, open(models_dir + '/model.pkl', 'wb'))\n",
    "pickle.dump(encoder, open(models_dir + '/encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = grid_search.cv_results_['rank_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'rank': ranks,\n",
    "    'class_weight': [p['class_weight'] for p in params],\n",
    "    'criterion': [p['criterion'] for p in params],\n",
    "    'max_depth': [p['max_depth'] for p in params],\n",
    "    'max_features': [p['max_features'] for p in params],\n",
    "    'n_estimators': [p['n_estimators'] for p in params],\n",
    "    'score': scores\n",
    "})\n",
    "\n",
    "results.set_index('rank', inplace=True)\n",
    "results.dropna(subset=['score'], inplace=True)\n",
    "results.sort_values(by='score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.130011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.129973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.129856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.129681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.129667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.129547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.129496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.129489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.128940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.128561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.128288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.127931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.127563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.126691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.122646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.122618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.122528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.122481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.122207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.122206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.122176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.121999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.090315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.087494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.086376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.084230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.083750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.083263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.083231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.083107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.082549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.082350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.082121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.081996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.081599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.080868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.080385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.078841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.069933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.066912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.065213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.064601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.063450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.062764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.062609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.058491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.004496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.004476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.004339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>500</td>\n",
       "      <td>0.003473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.003272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            class_weight criterion  max_depth max_features  n_estimators     score\n",
       "rank                                                                              \n",
       "1     balanced_subsample   entropy        5.0         sqrt          2000  0.130011\n",
       "2               balanced   entropy        5.0         sqrt           500  0.129973\n",
       "3     balanced_subsample   entropy        5.0         sqrt           500  0.129856\n",
       "4     balanced_subsample   entropy        5.0         log2          2000  0.129681\n",
       "5               balanced   entropy        5.0         log2          2000  0.129667\n",
       "6               balanced   entropy        5.0         sqrt          2000  0.129547\n",
       "7     balanced_subsample   entropy        5.0         sqrt          1000  0.129496\n",
       "8               balanced   entropy        5.0         sqrt          1000  0.129489\n",
       "9     balanced_subsample   entropy        5.0         log2          1000  0.128940\n",
       "10    balanced_subsample   entropy        5.0         log2           100  0.128932\n",
       "11              balanced   entropy        5.0         log2          1000  0.128561\n",
       "12    balanced_subsample   entropy        5.0         sqrt           100  0.128288\n",
       "13    balanced_subsample   entropy        5.0         log2           500  0.127931\n",
       "14              balanced   entropy        5.0         log2           500  0.127563\n",
       "15              balanced   entropy        5.0         sqrt           100  0.127500\n",
       "16              balanced   entropy        5.0         log2           100  0.126691\n",
       "17    balanced_subsample   entropy        5.0         None          2000  0.122646\n",
       "18    balanced_subsample   entropy        5.0         None          1000  0.122618\n",
       "19              balanced   entropy        5.0         None          2000  0.122528\n",
       "20              balanced   entropy        5.0         None          1000  0.122481\n",
       "21    balanced_subsample   entropy        5.0         None           100  0.122207\n",
       "22    balanced_subsample   entropy        5.0         None           500  0.122206\n",
       "23              balanced   entropy        5.0         None           500  0.122176\n",
       "24              balanced   entropy        5.0         None           100  0.121999\n",
       "25              balanced   entropy       20.0         log2           100  0.090315\n",
       "26              balanced   entropy       20.0         log2           500  0.087494\n",
       "27              balanced   entropy       20.0         None           100  0.086376\n",
       "28    balanced_subsample   entropy       20.0         None           100  0.084230\n",
       "29    balanced_subsample   entropy       20.0         None           500  0.083750\n",
       "30    balanced_subsample   entropy       20.0         log2          2000  0.083263\n",
       "31              balanced   entropy       20.0         None          1000  0.083231\n",
       "32    balanced_subsample   entropy       20.0         None          1000  0.083107\n",
       "33    balanced_subsample   entropy       20.0         None          2000  0.082549\n",
       "34    balanced_subsample   entropy       20.0         log2           500  0.082350\n",
       "35              balanced   entropy       20.0         None          2000  0.082121\n",
       "36              balanced   entropy       20.0         None           500  0.081996\n",
       "37              balanced   entropy       20.0         log2          2000  0.081599\n",
       "38    balanced_subsample   entropy       20.0         log2           100  0.080868\n",
       "39              balanced   entropy       20.0         log2          1000  0.080385\n",
       "40    balanced_subsample   entropy       20.0         log2          1000  0.078841\n",
       "41              balanced   entropy       20.0         sqrt           100  0.069933\n",
       "42    balanced_subsample   entropy       20.0         sqrt           100  0.066912\n",
       "43    balanced_subsample   entropy       20.0         sqrt          1000  0.065213\n",
       "44    balanced_subsample   entropy       20.0         sqrt           500  0.064601\n",
       "45    balanced_subsample   entropy       20.0         sqrt          2000  0.063450\n",
       "46              balanced   entropy       20.0         sqrt          2000  0.062764\n",
       "47              balanced   entropy       20.0         sqrt          1000  0.062609\n",
       "48              balanced   entropy       20.0         sqrt           500  0.058491\n",
       "49              balanced   entropy        NaN         None           500  0.004496\n",
       "50    balanced_subsample   entropy        NaN         None          1000  0.004484\n",
       "51    balanced_subsample   entropy        NaN         None          2000  0.004476\n",
       "52              balanced   entropy        NaN         None          2000  0.004339\n",
       "53    balanced_subsample   entropy        NaN         None           500  0.003473\n",
       "54    balanced_subsample   entropy        NaN         None           100  0.003272\n",
       "55              balanced   entropy        NaN         None          1000  0.003261\n",
       "56              balanced   entropy        NaN         sqrt           100  0.002188\n",
       "57              balanced   entropy        NaN         None           100  0.002000\n",
       "58    balanced_subsample   entropy        NaN         log2          2000  0.000000\n",
       "58              balanced   entropy        NaN         sqrt          2000  0.000000\n",
       "58              balanced   entropy        NaN         log2          2000  0.000000\n",
       "58              balanced   entropy        NaN         log2          1000  0.000000\n",
       "58              balanced   entropy        NaN         log2           500  0.000000\n",
       "58              balanced   entropy        NaN         log2           100  0.000000\n",
       "58              balanced   entropy        NaN         sqrt          1000  0.000000\n",
       "58    balanced_subsample   entropy        NaN         log2          1000  0.000000\n",
       "58              balanced   entropy        NaN         sqrt           500  0.000000\n",
       "58    balanced_subsample   entropy        NaN         sqrt           100  0.000000\n",
       "58    balanced_subsample   entropy        NaN         sqrt          1000  0.000000\n",
       "58    balanced_subsample   entropy        NaN         sqrt          2000  0.000000\n",
       "58    balanced_subsample   entropy        NaN         log2           100  0.000000\n",
       "58    balanced_subsample   entropy        NaN         log2           500  0.000000\n",
       "58    balanced_subsample   entropy        NaN         sqrt           500  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "589d2f16c7c43e145ee42078413b0251fb200486a68306d3d62712e3312580ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
